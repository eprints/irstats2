#!/usr/bin/perl -w

use strict;

# The script should be installed in $EPRINTS_PATH/ingredients/irstats2/bin/stats/
use FindBin;
use lib "$FindBin::Bin/../../../../perl_lib";

use Getopt::Long;
use Pod::Usage;
use EPrints;

our $verbose = 0;
my $help = 0;

Getopt::Long::Configure("permute");

my $constraints = { };

GetOptions(
	'verbose' => \$verbose,
	'min-accessid=i' => \$constraints->{min_accessid},
	'max-accessid=i' => \$constraints->{max_accessid},
	'min-date=s' => \$constraints->{min_date},
	'max-date=s' => \$constraints->{max_date},
	'help|?' => \$help,

) || pod2usage( 2 );

# Set STDOUT to auto flush (without needing a \n)
$|=1;

my $repoid = shift @ARGV;
if( $help )
{
	&usage();
	exit;
}

unless( defined $repoid )
{
	&usage();
	exit;
}

my $session = new EPrints::Session( 1, $repoid );
unless( defined $session )
{
	print STDERR "Could not load archive '$repoid'\n";
	exit;
}

my $handler = $session->plugin( "Stats::Handler", noise => $verbose );
unless($handler)
{
	print STDERR "FATAL ERROR: Stats handler (Stats::Handler.pm) not available\n";
	$session->terminate();
	exit;
}

if( $constraints->{min_date} && !( $constraints->{min_date} =~ /^(\d{4})-(\d{2})-(\d{2})$/ ) )
{
	print STDERR "FATAL ERROR: Failed to parse date '" . $constraints->{min_date} . "'\n";
	exit 1;
}

if( $constraints->{max_date} && !( $constraints->{max_date} =~ /^(\d{4})-(\d{2})-(\d{2})$/ ) )
{
	print STDERR "FATAL ERROR: Failed to parse date '" . $constraints->{max_date} . "'\n";
	exit 1;
}

process_access_dataset( $session, $handler, $constraints );

$session->terminate;
exit;

# ----------------------------------------------------------------------------

sub usage
{
	print <<USAGE;

$0 ARCHIVE_ID [--verbose] [--help]
     [--min-accessid MIN_ACCESS_ID] [--max-accessid MAX_ACCESS_ID]
     [--min-date MIN_DATE] [--max-date MAX_DATE]

    --verbose         displays extra information (useful for debugging).
    --help            this help.
    --min-accessid    imports records from this access id onwards.
    --max-accessid    imports records up until and including this access id.
    --min-date        imports records from this date onwards (YYYY-MM-DD).
    --max-date        imports records up until and including this date (YYYY-MM-DD).

USAGE
}

# This method generates the SQL to retrieve the current Access records and returns them wrapped into a IRStatsRecordList object (see below)
# Note that we cannot use the EPrints Search (too slow for the potential amount of records)
# Note that we cannot return ALL the records in one go in an array(-ref) (use far too much memory)
sub get_records
{
	my( $database, $constraints ) = @_;

	my @fields = (qw{
		accessid
		datestamp_year
		datestamp_month
		datestamp_day
		datestamp_hour
		datestamp_minute
		datestamp_second
		requester_id
		requester_user_agent
		referring_entity_id
		service_type_id
		referent_id
		referent_docid
	});

	my $dbh = $database->{dbh};

	my $Q_fields = {};
	my @Q_fields = ();

	foreach( @fields )
	{
		$Q_fields->{$_} = $dbh->quote_identifier( $_ );
		push @Q_fields, $Q_fields->{$_};
	}

	my $Q_table = $dbh->quote_identifier( 'access' );

	my $Q_datestamp_year = $dbh->quote_identifier( 'datestamp_year' );
	my $Q_datestamp_month = $dbh->quote_identifier( 'datestamp_month' );
	my $Q_datestamp_day = $dbh->quote_identifier( 'datestamp_day' );

	my $sql = "SELECT ".join(",",@Q_fields)." FROM $Q_table";

	my @conditions;

	if( defined $constraints->{min_accessid} && ( $constraints->{min_accessid} =~ /^[0-9]+$/ ) )
	{
		my $Q_access = $dbh->quote_identifier( 'accessid' );
		my $Q_accessid = $constraints->{min_accessid};
		push @conditions, "$Q_access >= $Q_accessid";
	}

	if( defined $constraints->{max_accessid} && ( $constraints->{max_accessid} =~ /^[0-9]+$/ ) )
	{
		my $Q_access = $dbh->quote_identifier( 'accessid' );
		my $Q_accessid = $constraints->{max_accessid};
		push @conditions, "$Q_access <= $Q_accessid";
	}

	if( defined $constraints->{min_date} )
	{
		if( $constraints->{min_date} =~ /^(\d{4})-(\d{2})-(\d{2})$/ )
		{
			my $year = $1;
			my $month = $2;
			my $day = $3;

			push @conditions,
				"(($Q_datestamp_year > $year) OR " .
				"(($Q_datestamp_year = $year) AND (($Q_datestamp_month > $month) OR " .
				"(($Q_datestamp_month = $month) AND ($Q_datestamp_day >= $day)))))";
		}
	}

	if( defined $constraints->{max_date} )
	{
		if( $constraints->{max_date} =~ /^(\d{4})-(\d{2})-(\d{2})$/ )
		{
			my $year = $1;
			my $month = $2;
			my $day = $3;

			push @conditions,
				"(($Q_datestamp_year < $year) OR " .
				"(($Q_datestamp_year = $year) AND (($Q_datestamp_month < $month) OR " .
				"(($Q_datestamp_month = $month) AND ($Q_datestamp_day <= $day)))))";
		}
	}

	if( scalar(@conditions) )
	{
		$sql .= " WHERE ".join( " AND ", @conditions );
	}

	my $list = IRStatsRecordList->new( dbh => $database, rawsql => $sql );
	return $list;
}

# This handles records coming from the Access dataset. "Records" are not true EPrint Dataobj, instead they are pre-processed HASH'es.
#
# Note also that this class does NOT use the EPrints API to retrieve records (EPrints::List and EPrints::Search especially) because they cannot cope well with
#  large amount of data (Access tables may contains 10's of millions of records). So this class implements its own data retrieval techniques. Note that this
#  was especially a problem on Oracle.
#
sub process_access_dataset
{
	my( $self, $handler, $constraints ) = @_;

	my $database = $self->{database};
	my $dbh = $database->{dbh};

	my $current_accessid = 0;

	my $global_ref_time = time;
	my $global_records_parsed = 0;

        my $logger = $self->plugin( "Stats::Logger" );

	# the get_records() method handles incremental SQL processing (it doesn't retrieve ALL the records in one go)
	my $records_list = get_records( $database, $constraints );

	$records_list->map( sub
	{
		my( undef, undef, $record, $info ) = @_;

		$logger->create_access({
			'datestamp' => EPrints::Time::iso_datetime( $record->{datestamp}->{epoch} ),
			'referring_entity_id' => $record->{referring_entity_id},
			'requester_id' => $record->{requester_id},
			'service_type_id' => $record->{service_type_id},
			'requester_user_agent' => $record->{requester_user_agent},
			'referent_id' => $record->{referent_id},
			'referent_docid' => $record->{referent_docid} ? $record->{referent_docid} : '',
		});

		if( $global_records_parsed > 0 && $global_records_parsed % 100_000 == 0 )
		{
			$handler->log( "Access: processed $global_records_parsed records so far." );
		}

		$global_records_parsed++;
	}, {} );
}

# This "internal" package is a replacement for EPrints::List for larger datasets.

package IRStatsRecordList;

use strict;
use Time::Local 'timegm_nocheck';

sub new
{
	my( $class, %opts ) = @_;

	my $self = bless \%opts, $class;

	$self->{idx} = 0;
	$self->{offset} = 0;
	$self->{limit} ||= 100_000;	# 100,000 records in one go maximum!
	$self->{records} = [];

	$self->init_query();

	return $self;
}

sub init_query
{
	my( $self ) = @_;

	my $sql = $self->{rawsql};

	my %o;
	$o{limit} = $self->{limit};
	$o{offset} = $self->{offset};

        my $sth = $self->{dbh}->prepare_select( $sql, %o );	#limit => $self->{limit}, offset => $self->{offset} );

        $self->{dbh}->execute( $sth, $sql );

	$self->{sth} = $sth;
}

# not reliable if the number of rows returned by the SQL statement is != to $self->{limit} (i.e. there are less rows than the LIMIT).
# note than on DBI there are no reliable ways to count the number of SELECT'ed rows rather than fetching them all and keeping a count.
sub is_last
{
	my( $self ) = @_;

	return ( $self->{idx} == $self->{limit} - 1 ) ? 1:0;
}

sub map
{
	my( $self, $fn, $info ) = @_;

	my $record;
        while ( $record = $self->next )
        {
		&{$fn}( undef, undef, $record, $info );
	}

	return;
}

sub next
{
	my( $self ) = @_;

	if( $self->{idx} >= $self->{limit} - 1 )
	{
		$self->{offset} += $self->{limit};
		$self->{idx} = 0;
		$self->init_query;
	}

	$self->{idx}++;
	my $row = $self->{sth}->fetchrow_arrayref;

	return $self->transform( $row );
}

sub transform
{
	my( $self, $row ) = @_;

	return undef unless( defined $row && scalar( @$row ) );

	my $h = {
		accessid => $row->[0],
		requester_id => $row->[7],
		requester_user_agent => $row->[8],
		referring_entity_id => $row->[9],
		service_type_id => $row->[10],
		referent_id => $row->[11],
		referent_docid => $row->[12],
	};

	my $hour = sprintf( "%02d", $row->[4] );
	my $day = sprintf( "%02d", $row->[3]);
	my $month = sprintf( "%02d", $row->[2]);
	my $year = $row->[1];

	$h->{datestamp} = {
		hour => $hour, day => $day, month => $month, year => $year,
		cache => "$year$month$day",
		epoch => timegm_nocheck $row->[6]||0,$row->[5]||0,$row->[4],$row->[3],$row->[2]-1,$row->[1]-1900,
	};

	$self->{last_record} = $h;

	return $h;
}

sub last
{
	my( $self ) = @_;

	return $self->{last_record};
}

1;
